{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from dataset import ImageDataset, TRANSFORM, LABEL_ID_INV_DIC\n",
    "from models import ResnetPredictor\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import hashlib\n",
    "import shutil\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.metrics.pairwise as metrics\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "DATA_DIR = \"../imagenette\"\n",
    "DATA_FILE = \"noisy_imagenette.csv\"\n",
    "\n",
    "MODEL_DIR = \"../models\"\n",
    "MODEL_FILE = \"resnet_state_dict.pth\"\n",
    "\n",
    "CONCEPT_DIR = \"../concepts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory deleted : ../concepts\\n03888257\n"
     ]
    }
   ],
   "source": [
    "def delete_subdirectories(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(\"Path does not lead to a valid directory.\")\n",
    "        return\n",
    "    \n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "            print(f\"Directory deleted : {item_path}\")\n",
    "\n",
    "folder_path = CONCEPT_DIR\n",
    "delete_subdirectories(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(addresses, images):\n",
    "    if not isinstance(addresses, list):\n",
    "        image_addresses = []\n",
    "        for i, image in enumerate(images):\n",
    "            image_name = \"0\" * (3 - int(np.log10(i + 1))) + str(i + 1) + \".png\"\n",
    "            image_addresses.append(os.path.join(addresses, image_name))\n",
    "            addresses = image_addresses\n",
    "    assert len(addresses) == len(images), \"Invalid number of addresses\"\n",
    "    for address, image in zip(addresses, images):\n",
    "        with open(address, \"wb\") as f:\n",
    "            Image.fromarray(image).save(f, format=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptDiscovery:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        data_file,\n",
    "        label,\n",
    "        image_shape,\n",
    "        average_image_value,\n",
    "        model,\n",
    "        bottleneck,\n",
    "        concept_dir,\n",
    "        max_imgs=40,\n",
    "        min_imgs=20,\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_file = data_file\n",
    "        self.concept_dir = concept_dir\n",
    "        if not os.path.exists(self.concept_dir):\n",
    "            os.makedirs(self.concept_dir)\n",
    "\n",
    "        self.label = label\n",
    "\n",
    "        self.image_shape = image_shape\n",
    "        self.average_image_value = average_image_value\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.bottleneck = bottleneck\n",
    "\n",
    "        self.max_imgs = max_imgs\n",
    "        self.min_imgs = min_imgs\n",
    "\n",
    "    def extract_discovery_images(self, n_image):\n",
    "        data_df = pd.read_csv(osp.join(self.data_dir, self.data_file))\n",
    "\n",
    "        label_data_df = data_df[data_df.noisy_labels_0 == self.label]\n",
    "        label_data_df = label_data_df[:n_image]\n",
    "\n",
    "        label_data_df.to_csv(\n",
    "            osp.join(self.data_dir, self.label + \"_\" + str(n_image) + \"_discovery_images.csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    def create_patches(self, param_dict):\n",
    "\n",
    "        if param_dict is None:\n",
    "            param_dict = {}\n",
    "\n",
    "        discovery_image_file = param_dict.pop(\"discovery_image_file\", None)\n",
    "        n_image = param_dict.pop(\"n_image\", 50)\n",
    "\n",
    "        n_segment = param_dict.pop(\"n_segment\", [15, 50, 80])\n",
    "        compactness = param_dict.pop(\"compactness\", 20)\n",
    "        sigma = param_dict.pop(\"sigma\", 1.0)\n",
    "\n",
    "        if discovery_image_file is None:\n",
    "            discovery_image_file = self.label + \"_\" + str(n_image) + \"_discovery_images.csv\"\n",
    "            if not osp.exists(osp.join(self.data_dir, discovery_image_file)):\n",
    "                self.extract_discovery_images(n_image)\n",
    "        else:\n",
    "            if not osp.exists(osp.join(self.data_dir, discovery_image_file)):\n",
    "                raise ValueError(\"File does not exist.\")\n",
    "            \n",
    "        discovery_image_dataset = ImageDataset(\n",
    "            self.data_dir, discovery_image_file, TRANSFORM, False\n",
    "        )\n",
    "        self.discovery_image_dataset = discovery_image_dataset\n",
    "\n",
    "        # Generate a unique identifier for the parameter set\n",
    "        param_str = f\"{n_segment}_{compactness}_{sigma}\"\n",
    "        param_hash = hashlib.md5(param_str.encode()).hexdigest()\n",
    "        subfolder = osp.join(self.data_dir, self.label + \"_\" + param_hash)\n",
    "        if not osp.exists(subfolder):\n",
    "            os.makedirs(subfolder)\n",
    "        patch_param_file = osp.join(subfolder, \"patch_params.npy\")\n",
    "        dataset_file = osp.join(subfolder, \"dataset.npy\")\n",
    "        image_numbers_file = osp.join(subfolder, \"image_numbers.npy\")\n",
    "        patches_file = osp.join(subfolder, \"patches.npy\")\n",
    "\n",
    "        # Check if existing patches and parameters match\n",
    "        if (\n",
    "            osp.exists(patch_param_file)\n",
    "            and osp.exists(dataset_file)\n",
    "            and osp.exists(image_numbers_file)\n",
    "            and osp.exists(patches_file)\n",
    "        ):\n",
    "            saved_params = np.load(patch_param_file, allow_pickle=True).item()\n",
    "            if (\n",
    "                saved_params[\"n_segment\"] == n_segment\n",
    "                and saved_params[\"compactness\"] == compactness\n",
    "                and saved_params[\"sigma\"] == sigma\n",
    "            ):\n",
    "                self.dataset = np.load(dataset_file)\n",
    "                self.image_numbers = np.load(image_numbers_file)\n",
    "                self.patches = np.load(patches_file)\n",
    "                print(\"Loaded existing patches and parameters from\", subfolder)\n",
    "                return\n",
    "\n",
    "        # Extract patches if non existent\n",
    "        dataset, image_numbers, patches = [], [], []\n",
    "\n",
    "        for i in tqdm(range(len(discovery_image_dataset)), desc=\"Superpixels and Patches\"):\n",
    "            img, _ = discovery_image_dataset[i]\n",
    "            img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "\n",
    "            image_superpixels, image_patches = self._return_superpixels(\n",
    "                img, n_segment, compactness, sigma\n",
    "            )\n",
    "\n",
    "            for superpixel, patch in zip(image_superpixels, image_patches):\n",
    "                dataset.append(superpixel)\n",
    "                patches.append(patch)\n",
    "                image_numbers.append(i)\n",
    "\n",
    "        self.dataset, self.image_numbers, self.patches = (\n",
    "            np.array(dataset),\n",
    "            np.array(image_numbers),\n",
    "            np.array(patches),\n",
    "        )\n",
    "\n",
    "        # Save patches and parameters to files with unique identifier\n",
    "        np.save(\n",
    "            patch_param_file, {\"n_segment\": n_segment, \"compactness\": compactness, \"sigma\": sigma}\n",
    "        )\n",
    "        np.save(dataset_file, self.dataset)\n",
    "        np.save(image_numbers_file, self.image_numbers)\n",
    "        np.save(patches_file, self.patches)\n",
    "\n",
    "    def _return_superpixels(self, image, n_segment=[15, 50, 80], compactness=20, sigma=1.0):\n",
    "\n",
    "        if not isinstance(n_segment, list):\n",
    "            n_segments = [n_segment]\n",
    "        else:\n",
    "            n_segments = n_segment\n",
    "\n",
    "        unique_masks = []\n",
    "        for i, n_segment in enumerate(n_segments):\n",
    "            segments = slic(\n",
    "                image,\n",
    "                n_segments=n_segment,\n",
    "                compactness=compactness,\n",
    "                sigma=sigma,\n",
    "            )\n",
    "\n",
    "            param_masks = []\n",
    "            for s in range(segments.max()):\n",
    "                mask = (segments == s).astype(float)\n",
    "                unique = True\n",
    "                # negligiblity check\n",
    "                if np.mean(mask) < 0.001:\n",
    "                    unique = False\n",
    "                # similarity check\n",
    "                for seen_mask in unique_masks:\n",
    "                    jaccard = np.sum(seen_mask * mask) / np.sum((seen_mask + mask) > 0)\n",
    "                    if jaccard > 0.5:\n",
    "                        unique = False\n",
    "                        break\n",
    "                if unique:\n",
    "                    param_masks.append(mask)\n",
    "\n",
    "            unique_masks.extend(param_masks)\n",
    "\n",
    "        superpixels, patches = [], []\n",
    "        while unique_masks:\n",
    "            superpixel, patch = self._extract_patch(image, unique_masks.pop())\n",
    "            superpixels.append(superpixel)\n",
    "            patches.append(patch)\n",
    "\n",
    "        return superpixels, patches\n",
    "\n",
    "    def _extract_patch(self, image, mask):\n",
    "\n",
    "        mask_expanded = np.expand_dims(mask, -1)\n",
    "        patch = mask_expanded * image + (1 - mask_expanded) * float(self.average_image_value) / 255\n",
    "\n",
    "        ones = np.where(mask == 1)\n",
    "        h1, h2, w1, w2 = ones[0].min(), ones[0].max(), ones[1].min(), ones[1].max()\n",
    "        image = Image.fromarray((patch[h1:h2, w1:w2] * 255).astype(np.uint8))\n",
    "        image_resized = (\n",
    "            np.array(image.resize(self.image_shape[:2], Image.BICUBIC)).astype(float) / 255\n",
    "        )\n",
    "\n",
    "        return image_resized, patch\n",
    "\n",
    "    def discover_concepts(self, param_dict=None):\n",
    "\n",
    "        if param_dict is None:\n",
    "            param_dict = {}\n",
    "\n",
    "        activation_file = param_dict.pop(\"activation_file\", None)\n",
    "        batch_size = param_dict.pop(\"batch_size\", 64)\n",
    "\n",
    "        n_clusters = param_dict.pop(\"n_clusters\", 25)\n",
    "        save = param_dict.pop(\"save\", True)\n",
    "\n",
    "        # Activations\n",
    "        activations = self.load_activations(activation_file)\n",
    "        if activations is None or self.bottleneck not in activations.keys():\n",
    "            self.bottleneck_activations = self._patch_activations(batch_size)\n",
    "            self.save_activations(activation_file)\n",
    "        else:\n",
    "            self.bottleneck_activations = activations[self.bottleneck]       \n",
    "\n",
    "        # Concepts\n",
    "        self.bottleneck_dic = {}\n",
    "\n",
    "        self.bottleneck_dic[\"label\"], self.bottleneck_dic[\"cost\"], centers = self._cluster(\n",
    "            self.bottleneck_activations, n_clusters\n",
    "        )\n",
    "\n",
    "        concept_number = 0\n",
    "        self.bottleneck_dic[\"concepts\"] = []\n",
    "\n",
    "        for i in tqdm(range(self.bottleneck_dic[\"label\"].max() + 1), desc=\"Concept selection\"):\n",
    "            label_idxs = np.where(self.bottleneck_dic[\"label\"] == i)[0]\n",
    "\n",
    "            if len(label_idxs) > self.min_imgs:\n",
    "                concept_costs = self.bottleneck_dic[\"cost\"][label_idxs]\n",
    "                concept_idxs = label_idxs[np.argsort(concept_costs)[: self.max_imgs]]\n",
    "                concept_image_numbers = set(self.image_numbers[label_idxs])\n",
    "                discovery_size = len(self.discovery_image_dataset)\n",
    "\n",
    "                highly_common_concept = len(concept_image_numbers) > 0.5 * len(label_idxs)\n",
    "\n",
    "                mildly_common_concept = len(concept_image_numbers) > 0.25 * len(label_idxs)\n",
    "                mildly_populated_concept = len(concept_image_numbers) > 0.25 * discovery_size\n",
    "                cond2 = mildly_populated_concept and mildly_common_concept\n",
    "\n",
    "                non_common_concept = len(concept_image_numbers) > 0.1 * len(label_idxs)\n",
    "                highly_populated_concept = len(concept_image_numbers) > 0.5 * discovery_size\n",
    "                cond3 = non_common_concept and highly_populated_concept\n",
    "\n",
    "                if highly_common_concept or cond2 or cond3:\n",
    "                    concept_number += 1\n",
    "                    concept = \"concept{}\".format(concept_number)\n",
    "                    self.bottleneck_dic[\"concepts\"].append(concept)\n",
    "                    self.bottleneck_dic[concept] = {\n",
    "                        \"images\": self.dataset[concept_idxs],\n",
    "                        \"patches\": self.patches[concept_idxs],\n",
    "                        \"image_numbers\": self.image_numbers[concept_idxs],\n",
    "                    }\n",
    "                    self.bottleneck_dic[concept + \"_center\"] = centers[i]\n",
    "\n",
    "        self.bottleneck_dic.pop(\"label\", None)\n",
    "        self.bottleneck_dic.pop(\"cost\", None)\n",
    "\n",
    "        self.save_concepts()\n",
    "\n",
    "    def _patch_activations(self, batch_size=64, channel_mean=True):\n",
    "\n",
    "        if isinstance(self.model, ResnetPredictor):\n",
    "            bottleneck_name = \"resnet.\" + self.bottleneck\n",
    "\n",
    "        bottleneck_layer = None\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == bottleneck_name:\n",
    "                bottleneck_layer = module\n",
    "                break\n",
    "\n",
    "        activation = []\n",
    "\n",
    "        def hook(module, input, output):\n",
    "            activation.append(output.detach().cpu().numpy())\n",
    "\n",
    "        hook_handle = bottleneck_layer.register_forward_hook(hook)\n",
    "        for i in tqdm(range(int(self.dataset.shape[0] / batch_size) + 1), desc=\"Activations\"):\n",
    "            batch_input = self.dataset[i * batch_size : (i + 1) * batch_size]\n",
    "            batch_input = torch.tensor(np.transpose(batch_input, (0, 3, 1, 2))).float()\n",
    "            _ = self.model(batch_input)\n",
    "\n",
    "        hook_handle.remove()\n",
    "\n",
    "        activation = np.concatenate(activation, axis=0)\n",
    "\n",
    "        if channel_mean and len(activation.shape) > 3:\n",
    "            activation = np.mean(activation, axis=(1, 2))\n",
    "        else:\n",
    "            activation = np.reshape(activation, [activation.shape[0], -1])\n",
    "\n",
    "        return activation\n",
    "\n",
    "    def _cluster(self, acts, n_clusters=25):\n",
    "\n",
    "        centers = None\n",
    "        km = cluster.KMeans(n_clusters)\n",
    "        d = km.fit(acts)\n",
    "        centers = km.cluster_centers_\n",
    "\n",
    "        d = np.linalg.norm(np.expand_dims(acts, 1) - np.expand_dims(centers, 0), ord=2, axis=-1)\n",
    "        asg, cost = np.argmin(d, -1), np.min(d, -1)\n",
    "\n",
    "        if centers is None:  ## If clustering returned cluster centers, use medoids\n",
    "            centers = np.zeros((asg.max() + 1, acts.shape[1]))\n",
    "            cost = np.zeros(len(acts))\n",
    "            for cluster_label in range(asg.max() + 1):\n",
    "                cluster_idxs = np.where(asg == cluster_label)[0]\n",
    "                cluster_points = acts[cluster_idxs]\n",
    "                pw_distances = metrics.euclidean_distances(cluster_points)\n",
    "                centers[cluster_label] = cluster_points[np.argmin(np.sum(pw_distances, -1))]\n",
    "                cost[cluster_idxs] = np.linalg.norm(\n",
    "                    acts[cluster_idxs] - np.expand_dims(centers[cluster_label], 0), ord=2, axis=-1\n",
    "                )\n",
    "        return asg, cost, centers\n",
    "\n",
    "    # def save_activations(self, file_name=None):\n",
    "    #     if file_name is None:\n",
    "    #         file_name = \"patch_activations.pickle\"\n",
    "\n",
    "    #     activation_dict = {self.bottleneck: self.bottleneck_activations}\n",
    "\n",
    "    #     activations_dir = osp.join(\n",
    "    #         self.concept_dir,\n",
    "    #         self.label,\n",
    "    #         type(self.model).__name__,\n",
    "    #         self.bottleneck,\n",
    "    #         \"activations\",\n",
    "    #     )\n",
    "    #     os.makedirs(activations_dir, exist_ok=True)\n",
    "\n",
    "    #     file_path = osp.join(activations_dir, file_name)\n",
    "\n",
    "    #     with open(file_path, \"wb\") as f:\n",
    "    #         pickle.dump(activation_dict, f)\n",
    "\n",
    "    # def load_activations(self, file_name=None):\n",
    "    #     if file_name is None:\n",
    "    #         file_name = \"patch_activations.pickle\"\n",
    "\n",
    "    #     file_path = osp.join(\n",
    "    #         self.concept_dir,\n",
    "    #         self.label,\n",
    "    #         type(self.model).__name__,\n",
    "    #         self.bottleneck,\n",
    "    #         \"activations\",\n",
    "    #         file_name,\n",
    "    #     )\n",
    "\n",
    "    #     if osp.exists(file_path):\n",
    "    #         with open(file_path, \"rb\") as f:\n",
    "    #             activation_dict = pickle.load(f)\n",
    "    #         bottleneck_activations = activation_dict\n",
    "    #     else:\n",
    "    #         bottleneck_activations = None\n",
    "\n",
    "    #     return bottleneck_activations\n",
    "\n",
    "    def save_activations(self, file_name=None):\n",
    "        if file_name is None:\n",
    "            file_name = \"patch_activations.pickle\"\n",
    "\n",
    "        activations_dir = osp.join(\n",
    "            self.concept_dir,\n",
    "            self.label,\n",
    "            type(self.model).__name__,\n",
    "            \"activations\",\n",
    "        )\n",
    "        os.makedirs(activations_dir, exist_ok=True)\n",
    "\n",
    "        file_path = osp.join(activations_dir, file_name)\n",
    "        if osp.exists(file_path):\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                activation_dict = pickle.load(f)\n",
    "        else:\n",
    "            activation_dict = {}\n",
    "\n",
    "        activation_dict[self.bottleneck] = self.bottleneck_activations\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(activation_dict, f)\n",
    "    \n",
    "    def load_activations(self, file_name=None):\n",
    "        if file_name is None:\n",
    "            file_name = \"patch_activations.pickle\"\n",
    "\n",
    "        file_path = osp.join(\n",
    "            self.concept_dir,\n",
    "            self.label,\n",
    "            type(self.model).__name__,\n",
    "            \"activations\",\n",
    "            file_name,\n",
    "        )\n",
    "\n",
    "        if osp.exists(file_path):\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                activation_dict = pickle.load(f)\n",
    "            return activation_dict\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def save_concepts(self):\n",
    "        for concept in self.bottleneck_dic[\"concepts\"]:\n",
    "            patches_dir = osp.join(\n",
    "                self.concept_dir,\n",
    "                self.label,\n",
    "                type(self.model).__name__,\n",
    "                self.bottleneck,\n",
    "                concept + \"_patches\",\n",
    "            )\n",
    "            images_dir = osp.join(\n",
    "                self.concept_dir,\n",
    "                self.label,\n",
    "                type(self.model).__name__,\n",
    "                self.bottleneck,\n",
    "                concept,\n",
    "            )\n",
    "            os.makedirs(patches_dir, exist_ok=True)\n",
    "            os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "            patches = (np.clip(self.bottleneck_dic[concept][\"patches\"], 0, 1) * 256).astype(\n",
    "                np.uint8\n",
    "            )\n",
    "            images = (np.clip(self.bottleneck_dic[concept][\"images\"], 0, 1) * 256).astype(np.uint8)\n",
    "            image_numbers = self.bottleneck_dic[concept][\"image_numbers\"]\n",
    "\n",
    "            image_addresses, patch_addresses = [], []\n",
    "            for i in range(len(images)):\n",
    "                image_name = \"0\" * int(np.ceil(2 - np.log10(i + 1))) + \"{}_{}\".format(\n",
    "                    i + 1, image_numbers[i]\n",
    "                )\n",
    "                patch_addresses.append(os.path.join(patches_dir, image_name + \".png\"))\n",
    "                image_addresses.append(os.path.join(images_dir, image_name + \".png\"))\n",
    "\n",
    "            save_images(patch_addresses, patches)\n",
    "            save_images(image_addresses, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n03888257'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ImageDataset(DATA_DIR, DATA_FILE, TRANSFORM, False)\n",
    "toy_image, toy_label_vec = train_dataset[5000]\n",
    "toy_image = np.transpose(toy_image.numpy(), (1, 2, 0))\n",
    "toy_label = LABEL_ID_INV_DIC[torch.argmax(toy_label_vec).item()]\n",
    "toy_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResnetPredictor'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(osp.join(MODEL_DIR, MODEL_FILE))\n",
    "\n",
    "loaded_model = ResnetPredictor()\n",
    "loaded_model.load_state_dict(model_state_dict)\n",
    "loaded_model.eval()\n",
    "\n",
    "type(loaded_model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_discovery = ConceptDiscovery(\n",
    "    DATA_DIR,\n",
    "    DATA_FILE,\n",
    "    toy_label,\n",
    "    image_shape=(320, 320, 3),\n",
    "    average_image_value=115,\n",
    "    model=loaded_model,\n",
    "    bottleneck=\"avgpool\",\n",
    "    concept_dir=CONCEPT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing patches and parameters from ../imagenette\\n03888257_ad3617c91c903ff915e3913972217c63\n"
     ]
    }
   ],
   "source": [
    "param_dict = {\n",
    "    \"discovery_image_file\": None,\n",
    "    \"n_image\": 50,\n",
    "    \"n_segment\": [15, 50, 80],\n",
    "    \"compactness\": 20,\n",
    "    \"sigma\": 1.0,\n",
    "}\n",
    "\n",
    "concept_discovery.create_patches(param_dict=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Activations: 100%|██████████| 89/89 [03:54<00:00,  2.64s/it]\n",
      "Concept selection:   0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ConceptDiscovery' object has no attribute 'discovery_image_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m param_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_activations\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m }\n\u001b[1;32m----> 9\u001b[0m \u001b[43mconcept_discovery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscover_concepts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 222\u001b[0m, in \u001b[0;36mConceptDiscovery.discover_concepts\u001b[1;34m(self, param_dict)\u001b[0m\n\u001b[0;32m    220\u001b[0m concept_idxs \u001b[38;5;241m=\u001b[39m label_idxs[np\u001b[38;5;241m.\u001b[39margsort(concept_costs)[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_imgs]]\n\u001b[0;32m    221\u001b[0m concept_image_numbers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_numbers[label_idxs])\n\u001b[1;32m--> 222\u001b[0m discovery_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscovery_image_dataset\u001b[49m)\n\u001b[0;32m    224\u001b[0m highly_common_concept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(concept_image_numbers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_idxs)\n\u001b[0;32m    226\u001b[0m mildly_common_concept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(concept_image_numbers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_idxs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConceptDiscovery' object has no attribute 'discovery_image_dataset'"
     ]
    }
   ],
   "source": [
    "param_dict = {\n",
    "    \"load_activations\": True,\n",
    "    \"activation_file\": None,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_clusters\": 25,\n",
    "    \"save\": True\n",
    "}\n",
    "\n",
    "concept_discovery.discover_concepts(param_dict=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConceptDiscovery' object has no attribute 'bottleneck_activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconcept_discovery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbottleneck_activations\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConceptDiscovery' object has no attribute 'bottleneck_activations'"
     ]
    }
   ],
   "source": [
    "concept_discovery.bottleneck_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_discovery.save_activations(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concept_discovery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconcept_discovery\u001b[49m\u001b[38;5;241m.\u001b[39mbottleneck_dic\n\u001b[0;32m      2\u001b[0m concept_discovery\u001b[38;5;241m.\u001b[39mbottleneck_dic\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m      3\u001b[0m concept_discovery\u001b[38;5;241m.\u001b[39mbottleneck_dic[concept_discovery\u001b[38;5;241m.\u001b[39mbottleneck_dic[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcepts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'concept_discovery' is not defined"
     ]
    }
   ],
   "source": [
    "concept_discovery.bottleneck_dic\n",
    "concept_discovery.bottleneck_dic.keys()\n",
    "concept_discovery.bottleneck_dic[concept_discovery.bottleneck_dic[\"concepts\"][0]]\n",
    "concept_discovery.bottleneck_dic[concept_discovery.bottleneck_dic[\"concepts\"][0]].keys()\n",
    "concept_discovery.bottleneck_dic[concept_discovery.bottleneck_dic[\"concepts\"][0]][\"images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del concept_discovery.dataset  \n",
    "del concept_discovery.image_numbers\n",
    "del concept_discovery.patches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-concepts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
